<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    img {
      name: 'YichenJiang_circle';
      class: 'circle';
      border-radius: 50%;
    } 
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Yichen Jiang</title>
  <!-- <meta http-equiv="Content-Type" content="text/html; charset=us-ascii"> -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Yichen Jiang (姜翌辰）</name>
              </p>
              <p>I'm a 3rd-year PhD student (8th-year Tar Heel) at <a href="https://www.cs.unc.edu/">Department of Computer Science</a> at <a href="https://www.unc.edu">University of North Carolina at Chapel Hill</a>, where I have spent the last 5 years pursuing my bachelor and master degree. I am advised by <a href="https://www.cs.unc.edu/~mbansal/"> Prof. Mohit Bansal</a> and work in <a href="http://nlp.cs.unc.edu/"> UNC-NLP </a> Research Group. My research focuses on Natural Language Processing and structured Deep Learning. In general, I build intuitive and interpretable Neural Network models to tackle some of the most challenging Natural Language Generation (NLG) (e.g., text summarization), and Natural Language Understanding (NLU) (e.g., machine reading-comprehension).
              </p>
              
              <p align=center>
                <a href="mailto:yichenj@cs.unc.edu">Email</a> &nbsp/&nbsp
                <a href="YichenJiang_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/jiangycTarheel">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=JgrPIsgAAAAJ&hl=en"> Google Scholar </a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/yichen-jiang-943355121/"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="YichenJiang_circle.png", name="YichenJiang_circle", class="circle", style="width:300px">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                I'm interested in natural language processing, computer vision, multi-modal system, machine learning, statistics, optimization. My research interest centers on building interpretable neural networks that achieves state-of-the-art performace in tasks related to human language. 
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='white.png', style="width:180px"></div>
                <img src='white.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Inducing Transformer's Compositional Generalization Ability via Auxiliary Sequence Prediction Tasks</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang</strong> and <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Proceedings of <a href="https://2021.emnlp.org/">EMNLP 2021</a></em> 
              <br>
<!--               <a href="https://arxiv.org/abs/2106.01317">arxiv</a> /
              <a href="https://github.com/jiangycTarheel/TPT-Summ">code</a> /             
              <a href="tpt-2021.bib">bibtex</a> -->
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='white.png', style="width:180px"></div>
                <img src='white.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Learning and Analyzing Generation Order for\ Undirected Sequence Models</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang</strong> and <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Findings of <a href="https://2021.emnlp.org/">EMNLP 2021</a></em> 
              <br>
<!--               <a href="https://arxiv.org/abs/2106.01317">arxiv</a> /
              <a href="https://github.com/jiangycTarheel/TPT-Summ">code</a> /             
              <a href="tpt-2021.bib">bibtex</a> -->
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='TPT-Summ.png', style="width:180px"></div>
                <img src='TPT-Summ.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang</strong>, Asli Celikyilmaz, Paul Smolensky, Paul Soulus, Sudha Rao, Hamid Palangi, Roland Fernandez, Caitlin Smith, <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>, Jianfeng Gao
              <br>
              <em>Proceedings of <a href="https://2021.naacl.org/">NAACL-HLT 2021</a></em> 
              <br>
              <a href="https://arxiv.org/abs/2106.01317">arxiv</a> /
              <a href="https://github.com/jiangycTarheel/TPT-Summ">code</a> /             
              <a href="tpt-2021.bib">bibtex</a>
              <!-- <p>"Closed-book" decoder without attention or pointer mechanism can improve the representation power of the final memory state of the encoder in a pointer-generator seq-attention-seq model.</p>
              <p>This is important for model to generate salient summaries because the encoder is able to encode salient information from the source article and ignore other trivial information.</p> -->
            </td>
          </tr>
          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='hover.png', style="width:180px"></div>
                <img src='hover.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang*</strong>, Shikha Bordia*, Zheng Zhong, Charles Dognin, Maneesh Singh, <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Findings of <a href="https://2020.emnlp.org/">EMNLP 2020</a></em> 
              <br>
              <a href="https://arxiv.org/abs/2011.03088">arxiv</a> /
              <a href="https://hover-nlp.github.io/">data+code</a> /             
              <a href="hover-2020.bib">bibtex</a>
              <!-- <p>"Closed-book" decoder without attention or pointer mechanism can improve the representation power of the final memory state of the encoder in a pointer-generator seq-attention-seq model.</p>
              <p>This is important for model to generate salient summaries because the encoder is able to encode salient information from the source article and ignore other trivial information.</p> -->
            </td>
          </tr>
          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='nmn.png', style="width:180px"></div>
                <img src='nmn.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang</strong>, <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Proceedings of <a href="https://www.emnlp-ijcnlp2019.org">EMNLP 2019</a>, Hong Kong, China</em> 
              <br>
              <a href="https://arxiv.org/abs/1909.05803">arxiv</a> /
              <a href="https://github.com/jiangycTarheel/NMN-MultiHopQA">code</a> /             
              <a href="nmn-2019.bib">bibtex</a>
              <!-- <p>"Closed-book" decoder without attention or pointer mechanism can improve the representation power of the final memory state of the encoder in a pointer-generator seq-attention-seq model.</p>
              <p>This is important for model to generate salient summaries because the encoder is able to encode salient information from the source article and ignore other trivial information.</p> -->
            </td>
          </tr>
          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='adv-gen.png', style="width:180px"></div>
                <img src='adv-gen.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and Model Development for Multi-Hop QA</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang</strong>, <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Proceedings of <a href="http://www.acl2019.org/EN/index.xhtml">ACL 2019</a>, Florence, Italy</em> 
              <br>
              <a href="https://arxiv.org/abs/1906.07132">arxiv</a> /
              <a href="https://github.com/jiangycTarheel/Adversarial-MultiHopQA">code</a> /
              <a href="adv-hotpot2019_slides.pdf">slides</a> /
              <a href="adv-hotpot2019.bib">bibtex</a>
              <!-- <p>"Closed-book" decoder without attention or pointer mechanism can improve the representation power of the final memory state of the encoder in a pointer-generator seq-attention-seq model.</p>
              <p>This is important for model to generate salient summaries because the encoder is able to encode salient information from the source article and ignore other trivial information.</p> -->
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='epar.png', style="width:180px"></div>
                <img src='epar.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang*</strong>, Nitish Joshi*, Yen-chun Chen, and <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Proceedings of <a href="http://www.acl2019.org/EN/index.xhtml">ACL 2019</a>, Florence, Italy</em>
              <br>
              <a href="https://arxiv.org/abs/1906.05210">arxiv</a> /
              <a href="https://github.com/jiangycTarheel/EPAr">code</a> /    
              <a href="epar2019_slides.pdf">slides</a> /          
              <a href="epar2019.bib">bibtex</a>
              <!-- <p>"Closed-book" decoder without attention or pointer mechanism can improve the representation power of the final memory state of the encoder in a pointer-generator seq-attention-seq model.</p>
              <p>This is important for model to generate salient summaries because the encoder is able to encode salient information from the source article and ignore other trivial information.</p> -->
            </td>
          </tr>

          <tr onmouseout="portrait_stop()" onmouseover="portrait_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='portrait_image'><img src='2dec.png', style="width:180px"></div>
                <img src='2dec.png', style="width:180px">
              </div>
              <script type="text/javascript">
                function portrait_start() {
                  document.getElementById('portrait_image').style.opacity = "1";
                }

                function portrait_stop() {
                  document.getElementById('portrait_image').style.opacity = "0";
                }
                portrait_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <!-- <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing"> -->
                <papertitle>Closed-book Training to Improve Summarization Encoder Memory</papertitle>
              </a>
              <br>
              <strong>Yichen Jiang</strong>, <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>
              <br>
              <em>Proceedings of <a href="http://emnlp2018.org/">EMNLP 2018</a>, Brussels, Belgium</em>
              <br>
              <a href="https://arxiv.org/abs/1809.04585">arxiv</a> /
<!--               <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">blog post</a> /
 -->              
              <a href="closed-book2018_poster.pdf">poster</a> /
              <a href="closed-book2018.bib">bibtex</a>
              <!-- <p>"Closed-book" decoder without attention or pointer mechanism can improve the representation power of the final memory state of the encoder in a pointer-generator seq-attention-seq model.</p>
              <p>This is important for model to generate salient summaries because the encoder is able to encode salient information from the source article and ignore other trivial information.</p> -->
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="40%" valign="middle">
              <heading>Work/Intern Experience</heading>
<!--               <p>
                Verisk Analytics,
              </p> -->
            </td width="20%">
            <td>
            </td width="40%"> 
            <td>
            </td> 
          </tr>
          <tr>
            <td width="20%"><b>Facebook AI Research</b></td>
            <td>2021 May - 2021 August</td>
<!--             <td>Supervised by Dr. Maneesh Singh</td>
 -->          
          </tr>
          <tr>
            <td width="20%"><b>Microsoft Research, Redmond</b></td>
            <td>2020 June - 2020 August</td>
            <td>Supervised by Dr. Asli Celikyilmaz and Prof. Paul Smolensky</td>
          </tr>
          <tr>
            <td width="20%"><b>Verisk Analytics</b></td>
            <td>2019 May - 2019 August</td>
            <td>Supervised by Dr. Maneesh Singh</td>
          </tr>
          
        </table>
       <!--  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Course Projects</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="prl.jpg" alt="prl" width="160" height="160"></td>
            <td width="75%" valign="top">
              <p>
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <papertitle>Parallelizing Reinforcement Learning</papertitle>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>, 2009
                <p>
                  <br> Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.
                </p>
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="pacman.jpg" alt="pacman" width="160" height="160"></td>
            <td width="75%" valign="center">
              <p>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
                  <papertitle>CS188 - Fall 2010 (GSI)</papertitle>
                </a>
                <br>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
                  <papertitle>CS188 - Spring 2011 (GSI)</papertitle>
                </a>
                <br>
              </p>
            </td>
          </tr>
        </table> -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <a href="https://jonbarron.info/">Thanks for providing the template source code for this website </a>
              </p>
            </td>
          </tr>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
